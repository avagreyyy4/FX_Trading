{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f08f2e-f0af-4790-8620-d8800b40d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "import sklearn.datasets\n",
    "import sklearn.preprocessing\n",
    "import sklearn.random_projection\n",
    "import sklearn.neighbors\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ceed0a2-bee6-4074-a6bd-f4e9be16c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define patterns\n",
    "n = 5\n",
    "profit_taking = 0.0035\n",
    "p = 0.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57343a44-5c7e-4b93-b64d-ee3a504979cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5262, 11)\n"
     ]
    }
   ],
   "source": [
    "#READ IN DATA\n",
    "df_original = pd.read_csv(\"data/final_clean_FX_data.csv\")\n",
    "print(df_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e0fea9-6302-4dd1-a356-068580d3da94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3338, 55)\n"
     ]
    }
   ],
   "source": [
    "#feature engineer\n",
    "df_original = df_original.sort_values(by =  \"Date\", ascending=True)\n",
    "df = df_original\n",
    "df[\"c_over_o\"] = (df[\"Close\"] - df[\"Open\"]) / df[\"Open\"]\n",
    "df[\"h_over_o\"] = (df[\"High\"]  - df[\"Open\"]) / df[\"Open\"]\n",
    "df[\"l_over_o\"] = (df[\"Low\"]   - df[\"Open\"]) / df[\"Open\"]\n",
    "df[\"range\"] = (df[\"High\"] - df[\"Low\"]) / df[\"Open\"]\n",
    "\n",
    "\n",
    "# CREATE PRIOR n DAYS FEATURE\n",
    "for before in range(1, n+1):\n",
    "    df[f\"Close_{before}_before\"] = df[\"Close\"].shift(before)\n",
    "    df[f\"Open_{before}_before\"] = df[\"Open\"].shift(before)\n",
    "    df[f\"High_{before}_before\"] = df[\"High\"].shift(before)\n",
    "    df[f\"Low_{before}_before\"] = df[\"Low\"].shift(before)\n",
    "    df[f\"c_over_o_lag{before}\"] = df[\"c_over_o\"].shift(before)\n",
    "    df[f\"h_over_o_lag{before}\"] = df[\"h_over_o\"].shift(before)\n",
    "    df[f\"l_over_o_lag{before}\"] = df[\"l_over_o\"].shift(before)\n",
    "\n",
    "#feature enginnering\n",
    "df[\"range_lag1\"] = df[\"range\"].shift(1)\n",
    "df[\"range_5d\"] = df[\"range_lag1\"].rolling(5).mean()\n",
    "\n",
    "\n",
    "df[\"ret_1d\"] = np.log(df[\"Close\"]) - np.log(df[\"Close_1_before\"])\n",
    "df[\"ret_5d\"] = np.log(df[\"Close\"]) - np.log(df[\"Close_5_before\"])\n",
    "df[\"vol_5d\"]  = df[\"ret_1d\"].rolling(5).std()\n",
    "df[\"vol_10d\"] = df[\"ret_1d\"].rolling(10).std()\n",
    "df[\"mom_5d\"] = df[\"ret_1d\"].rolling(5).mean()\n",
    "df[\"mom_10d\"] = df[\"ret_1d\"].rolling(10).mean()\n",
    "\n",
    "\n",
    "feature_cols = [\n",
    "    \"ret_1d\", \"ret_5d\",\n",
    "    \"vol_5d\", \"vol_10d\",\n",
    "    \"mom_5d\", \"mom_10d\", \n",
    "    \"range_5d\"\n",
    "]\n",
    "\n",
    "df[feature_cols] = df[feature_cols].shift(1)\n",
    "\n",
    "df[\"target\"] = (df[\"High\"] > (profit_taking+1)*df[\"Open\"]).astype(int)\n",
    "target = df[[\"target\"]]\n",
    "df = df.dropna()\n",
    "df = df.drop(columns=['c_over_o', 'h_over_o', 'l_over_o', 'range'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aad8069-9747-4c90-b124-7b64f73a0441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1011, 55)\n"
     ]
    }
   ],
   "source": [
    "# make splits\n",
    "train_df   = df[(df['Date'] >= '2013-01-01') & (df['Date'] < '2020-01-01')]\n",
    "val_df   = df[(df['Date'] >= '2020-01-01') & (df['Date'] < '2022-01-01')]\n",
    "test_df  = df[df['Date'] >= '2022-01-01']\n",
    "\n",
    "x_train = train_df.drop(columns=['target', 'Date', 'Close', 'Open', 'High', 'Low'])\n",
    "y_train = train_df['target']\n",
    "\n",
    "x_val = val_df.drop(columns=['target', 'Date', 'Close', 'Open', 'High', 'Low'])\n",
    "y_val = val_df['target']\n",
    "\n",
    "x_test = test_df.drop(columns=['target', 'Date', 'Close', 'Open', 'High', 'Low'])\n",
    "y_test = test_df['target']\n",
    "\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "289744d4-c800-45db-9a5e-d046f5545b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "\n",
    "standardize = StandardScaler(with_mean=True, with_std=True)\n",
    "standardize.fit(x_train)\n",
    "x_train = pd.DataFrame(\n",
    "    standardize.transform(x_train),\n",
    "    columns=x_train.columns,\n",
    "    index=x_train.index\n",
    ")\n",
    "x_val = pd.DataFrame(\n",
    "    standardize.transform(x_val),\n",
    "    columns=x_val.columns,\n",
    "    index=x_val.index\n",
    ")\n",
    "x_test = pd.DataFrame(\n",
    "    standardize.transform(x_test),\n",
    "    columns=x_test.columns,\n",
    "    index=x_test.index\n",
    ")\n",
    "\n",
    "# pca\n",
    "#pca = sklearn.decomposition.PCA(n_components=15)\n",
    "#pca.fit(x_train)\n",
    "#x_train = pca.transform(x_train)\n",
    "#x_test = pca.transform(x_test)\n",
    "#x_val = pca.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "091e41eb-1a10-40b5-aacc-5e5fce2bbb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1804, 49)\n",
      "(523, 49)\n",
      "(1011, 49)\n",
      "target\n",
      "0    0.546009\n",
      "1    0.453991\n",
      "Name: proportion, dtype: float64\n",
      "target\n",
      "0    0.629063\n",
      "1    0.370937\n",
      "Name: proportion, dtype: float64\n",
      "target\n",
      "0    0.695351\n",
      "1    0.304649\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_val.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0775a3-d39a-4a1c-ad47-e5d869dfc0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 0.7754\n",
      "Val   ROC AUC: 0.6112\n",
      "Test ROC AUC: 0.6166\n"
     ]
    }
   ],
   "source": [
    "# MODEL TRAINING\n",
    "model1 = MLPClassifier(\n",
    "    hidden_layer_sizes=(16, 8),\n",
    "    activation=\"relu\",\n",
    "    alpha=0.001,\n",
    "    max_iter=2000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model1.fit(x_train, y_train)\n",
    "\n",
    "train_probs = model1.predict_proba(x_train)[:, 1]\n",
    "val_probs   = model1.predict_proba(x_val)[:, 1]\n",
    "\n",
    "train_auc = roc_auc_score(y_train, train_probs)\n",
    "val_auc   = roc_auc_score(y_val, val_probs)\n",
    "\n",
    "print(f\"Train ROC AUC: {train_auc:.4f}\")\n",
    "print(f\"Val   ROC AUC: {val_auc:.4f}\")\n",
    "\n",
    "if True:\n",
    "    test_probs   = model1.predict_proba(x_test)[:, 1]\n",
    "    test_auc   = roc_auc_score(y_test, test_probs)\n",
    "    print(f\"Test ROC AUC: {test_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9df008ac-e1a9-42ff-abec-4480b99ebf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.617\n",
      "\n",
      "===== HIT RATES =====\n",
      "Base hit rate: 0.304648862512364\n",
      "Hit rate on trades: 0.45634920634920634\n",
      "Coverage: 0.24925816023738873\n",
      "\n",
      "===== COMPOUNDED PERFORMANCE =====\n",
      "Baseline final equity:     0.9579\n",
      "Model final equity:        1.1418\n",
      "Baseline compounded return: -4.21%\n",
      "Model compounded return:    14.18%\n",
      "Compounded ABOVE baseline:  19.19%\n",
      "\n",
      "===== NON-COMPOUNDED PERFORMANCE (.sum OF RETURNS) =====\n",
      "Baseline non-compounded return: -3.8226%\n",
      "Model non-compounded return:    13.4102%\n",
      "NON-COMPOUNDED ABOVE BASELINE:  17.2328%\n",
      "\n",
      "===== TRADE COUNTS =====\n",
      "Baseline trades: 1011\n",
      "Model trades:    252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ======================================================\n",
    "# SETUP\n",
    "# ======================================================\n",
    "\n",
    "df_test = test_df.copy()\n",
    "\n",
    "# ======================================================\n",
    "# MODEL PROBABILITIES\n",
    "# ======================================================\n",
    "\n",
    "X_test = df_test.drop(columns=[\"target\", \"Date\", \"Close\", \"Open\", \"High\", \"Low\"])\n",
    "X_test = standardize.transform(X_test)\n",
    "\n",
    "probs = model1.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc = roc_auc_score(df_test[\"target\"], probs)\n",
    "print(f\"ROC-AUC: {auc:.3f}\")\n",
    "\n",
    "# ======================================================\n",
    "# HIT RATES\n",
    "# ======================================================\n",
    "\n",
    "base_hit_rate = df_test[\"target\"].mean()\n",
    "entered = probs >= p\n",
    "hit_rate_trades = df_test.loc[entered, \"target\"].mean()\n",
    "coverage = entered.mean()\n",
    "\n",
    "print(\"\\n===== HIT RATES =====\")\n",
    "print(\"Base hit rate:\", base_hit_rate)\n",
    "print(\"Hit rate on trades:\", hit_rate_trades)\n",
    "print(\"Coverage:\", coverage)\n",
    "\n",
    "# ======================================================\n",
    "# RETURNS (EXECUTION ONLY)\n",
    "# ======================================================\n",
    "\n",
    "df_test[\"ret_oc\"] = (df_test[\"Close\"] - df_test[\"Open\"]) / df_test[\"Open\"]\n",
    "\n",
    "# ======================================================\n",
    "# COMPOUNDED RETURNS\n",
    "# ======================================================\n",
    "\n",
    "def simulate_compounded_equity(df, enter_mask, profit_taking, start_equity=1.0):\n",
    "    equity = start_equity\n",
    "    equity_curve = []\n",
    "\n",
    "    for take_trade, (_, row) in zip(enter_mask, df.iterrows()):\n",
    "        if take_trade:\n",
    "            r = (\n",
    "                profit_taking\n",
    "                if row[\"High\"] >= (1 + profit_taking) * row[\"Open\"]\n",
    "                else row[\"ret_oc\"]\n",
    "            )\n",
    "            equity *= (1 + r)\n",
    "        equity_curve.append(equity)\n",
    "\n",
    "    return equity, equity_curve\n",
    "\n",
    "\n",
    "baseline_enter = np.ones(len(df_test), dtype=bool)\n",
    "\n",
    "baseline_final, baseline_curve = simulate_compounded_equity(\n",
    "    df_test, baseline_enter, profit_taking\n",
    ")\n",
    "\n",
    "model_final, model_curve = simulate_compounded_equity(\n",
    "    df_test, entered, profit_taking\n",
    ")\n",
    "\n",
    "baseline_comp_return = baseline_final - 1\n",
    "model_comp_return = model_final - 1\n",
    "compounded_above_baseline = model_final / baseline_final - 1\n",
    "\n",
    "print(\"\\n===== COMPOUNDED PERFORMANCE =====\")\n",
    "print(f\"Baseline final equity:     {baseline_final:.4f}\")\n",
    "print(f\"Model final equity:        {model_final:.4f}\")\n",
    "print(f\"Baseline compounded return: {baseline_comp_return:.2%}\")\n",
    "print(f\"Model compounded return:    {model_comp_return:.2%}\")\n",
    "print(f\"Compounded ABOVE baseline:  {compounded_above_baseline * 100:.2f}%\")\n",
    "\n",
    "# ======================================================\n",
    "# NON-COMPOUNDED RETURNS (PURE .sum() OF %)\n",
    "# ======================================================\n",
    "\n",
    "df_pnl = df_test.copy()\n",
    "df_pnl[\"enter\"] = entered.astype(int)\n",
    "\n",
    "df_pnl[\"daily_return\"] = 0.0\n",
    "\n",
    "# Model: TP hit\n",
    "df_pnl.loc[\n",
    "    (df_pnl[\"enter\"] == 1) &\n",
    "    (df_pnl[\"High\"] >= (1 + profit_taking) * df_pnl[\"Open\"]),\n",
    "    \"daily_return\"\n",
    "] = profit_taking\n",
    "\n",
    "# Model: TP not hit\n",
    "df_pnl.loc[\n",
    "    (df_pnl[\"enter\"] == 1) &\n",
    "    (df_pnl[\"High\"] < (1 + profit_taking) * df_pnl[\"Open\"]),\n",
    "    \"daily_return\"\n",
    "] = df_pnl[\"ret_oc\"]\n",
    "\n",
    "model_non_comp_return = df_pnl[\"daily_return\"].sum()\n",
    "model_trades = df_pnl[\"enter\"].sum()\n",
    "\n",
    "# ======================================================\n",
    "# BASELINE NON-COMPOUNDED\n",
    "# ======================================================\n",
    "\n",
    "df_base = df_test.copy()\n",
    "\n",
    "df_base[\"daily_return\"] = np.where(\n",
    "    df_base[\"High\"] >= (1 + profit_taking) * df_base[\"Open\"],\n",
    "    profit_taking,\n",
    "    df_base[\"ret_oc\"]\n",
    ")\n",
    "\n",
    "baseline_non_comp_return = df_base[\"daily_return\"].sum()\n",
    "baseline_trades = len(df_base)\n",
    "\n",
    "non_comp_above_baseline = model_non_comp_return - baseline_non_comp_return\n",
    "\n",
    "# ======================================================\n",
    "# FINAL SUMMARY (PRINT EVERYTHING)\n",
    "# ======================================================\n",
    "\n",
    "print(\"\\n===== NON-COMPOUNDED PERFORMANCE (.sum OF RETURNS) =====\")\n",
    "print(f\"Baseline non-compounded return: {baseline_non_comp_return:.4%}\")\n",
    "print(f\"Model non-compounded return:    {model_non_comp_return:.4%}\")\n",
    "print(f\"NON-COMPOUNDED ABOVE BASELINE:  {non_comp_above_baseline * 100:.4f}%\")\n",
    "\n",
    "print(\"\\n===== TRADE COUNTS =====\")\n",
    "print(f\"Baseline trades: {baseline_trades}\")\n",
    "print(f\"Model trades:    {model_trades}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
